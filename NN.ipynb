{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29823a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfc9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ece28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_myNNcv(model, X, y, chunk_size, batch_size, learning_rate=1e-3):\n",
    "    losses=[]\n",
    "    ce_loss = nn.BCEWithLogitsLoss()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    ds = Gen_Dataset(Xtrain, ytrain)\n",
    "    data_loader = DataLoader(ds, batch_size=batch_size)\n",
    "    for X, y in data_loader:\n",
    "        X = X.float()\n",
    "        if X.shape[0] < 10:\n",
    "            continue\n",
    "        y = y.float().view(-1, 1)\n",
    "        opt.zero_grad()\n",
    "        out = model(X)\n",
    "        loss = ce_loss(out, y)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return losses\n",
    "\n",
    "def test_myNNcv(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(X)\n",
    "        ypred = torch.round(out)\n",
    "        y = y.numpy()\n",
    "        acc = accuracy_score(ypred, y)\n",
    "        TP, FP, TN, FN = 0, 0, 0, 0\n",
    "        for i in range(len(ypred)):\n",
    "            if ypred[i] == 1 and ytest[i] == 1:\n",
    "                TP += 1\n",
    "            elif ypred[i] == 1 and ytest[i] == 0:\n",
    "                FP += 1\n",
    "            elif ypred[i] == 0 and ytest[i] == 0:\n",
    "                TN += 1    \n",
    "            elif ypred[i] == 0 and ytest[i] == 1:\n",
    "                FN += 1\n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "        print('Accuracy, Precision, Recall: ', np.round(acc, 3), np.round(precision, 3), np.round(recall, 3))\n",
    "    print('Finished all testing...')\n",
    "    return acc, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f0d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_myNN(model, file_list, chunk_size, batch_size, cols, learning_rate=1e-3):\n",
    "    losses=[]\n",
    "#     ce_loss = nn.BCELoss()\n",
    "    ce_loss = nn.BCEWithLogitsLoss()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    net.train()\n",
    "    for file in file_list:\n",
    "        path = 'D:\\\\Stock Data\\\\' + file\n",
    "        print('Training data file: ' + file)\n",
    "        for df in pd.read_csv(path, chunksize=chunk_size, usecols=cols):\n",
    "            if df.shape[0] < batch_size:\n",
    "                continue\n",
    "            Xtrain = df.drop(['labels'], axis=1)\n",
    "            ytrain = df['labels']\n",
    "            ds = Gen_Dataset(Xtrain, ytrain)\n",
    "            data_loader = DataLoader(ds, batch_size=batch_size)\n",
    "            for X, y in data_loader:\n",
    "                X = X.float()\n",
    "                if X.shape[0] < 10:\n",
    "                    continue\n",
    "                y = y.float().view(-1, 1)\n",
    "                opt.zero_grad()\n",
    "                out = net(X)\n",
    "                loss = ce_loss(out, y)\n",
    "                losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "#     return losses\n",
    "        print('Finished training ', file)\n",
    "    print('Finished all training...')\n",
    "    return losses\n",
    "\n",
    "def train_myNN2(model, file_list, chunk_size, batch_size, cols, learning_rate=1e-3, epochs=10):\n",
    "    losses=[]\n",
    "#     ce_loss = nn.BCELoss()\n",
    "    ce_loss = nn.BCEWithLogitsLoss()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    net.train()\n",
    "    for file in file_list:\n",
    "        path = 'D:\\\\Stock Data\\\\' + file\n",
    "        print('Training data file: ' + file)\n",
    "        for e in range(epochs):\n",
    "            for df in pd.read_csv(path, chunksize=chunk_size, usecols=cols):\n",
    "                if df.shape[0] < batch_size:\n",
    "                    continue\n",
    "                Xtrain = df.drop(['labels'], axis=1)\n",
    "                ytrain = df['labels']\n",
    "                ds = Gen_Dataset(Xtrain, ytrain)\n",
    "                data_loader = DataLoader(ds, batch_size=batch_size)\n",
    "                for X, y in data_loader:\n",
    "                    X = X.float()\n",
    "                    if X.shape[0] < 10:\n",
    "                        continue\n",
    "                    y = y.float().view(-1, 1)\n",
    "                    opt.zero_grad()\n",
    "                    out = net(X)\n",
    "                    loss = ce_loss(out, y)\n",
    "                    losses.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "#     return losses\n",
    "        print('Finished training ', file)\n",
    "    print('Finished all training...')\n",
    "    return losses\n",
    "\n",
    "def test_myNN(model, file_list, cols):\n",
    "    model.eval()\n",
    "    for file in file_list:\n",
    "        path = 'D:\\\\Stock Data\\\\' + file\n",
    "        print('Testing data file: ' + file)\n",
    "        df_test = pd.read_csv(path, usecols=cols)\n",
    "        Xtest = torch.tensor(df_test.drop(['labels'], axis=1).values).float()\n",
    "        ytest = torch.tensor(df_test['labels'].values).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(Xtest)\n",
    "            ypred = torch.round(out)\n",
    "            ytest = ytest.numpy()\n",
    "            acc = accuracy_score(ypred, ytest)\n",
    "        TP, FP, TN, FN = 0, 0, 0, 0\n",
    "        for i in range(len(ypred)):\n",
    "            if ypred[i] == 1 and ytest[i] == 1:\n",
    "                TP += 1\n",
    "            elif ypred[i] == 1 and ytest[i] == 0:\n",
    "                FP += 1\n",
    "            elif ypred[i] == 0 and ytest[i] == 0:\n",
    "                TN += 1    \n",
    "            elif ypred[i] == 0 and ytest[i] == 1:\n",
    "                FN += 1\n",
    "        precision = TP/(TP + FP)\n",
    "        recall = TP/(TP + FN)\n",
    "        print('Accuracy, Precision, Recall: ', np.round(acc, 3), np.round(precision, 3), np.round(recall, 3))\n",
    "    print('Finished all testing...')\n",
    "    \n",
    "class Gen_Dataset():\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values)\n",
    "        self.y = torch.tensor(y.values)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return (self.X[i, :], self.y[i])\n",
    "    \n",
    "class myNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNN, self).__init__()\n",
    "        self.hidden_nodes = 64\n",
    "        self.fc1 = nn.Linear(8, self.hidden_nodes)\n",
    "        self.fc2 = nn.Linear(self.hidden_nodes, self.hidden_nodes)\n",
    "        self.fc3 = nn.Linear(self.hidden_nodes, 1)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(self.hidden_nodes)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(self.hidden_nodes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9c0fc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chunk_size = 1e4\n",
    "batch_size = 128\n",
    "cols = ['PAST_1y_p90', 'leverage', 'leverage_mkt', \\\n",
    "        'bm', 'roe', 'lag_baspread', 'lag_liquidity', 'lag_size', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77221b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_train1.csv\n",
      "Finished training  data2000_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2000_test1.csv\n",
      "Accuracy, Precision, Recall:  0.885 0.148 0.005\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "net = myNN()\n",
    "file_list = ['data2000_train1.csv']\n",
    "test_file_list = ['data2000_test1.csv']\n",
    "learning_rate = 1e-4\n",
    "losses = train_myNN(model=net, file_list=file_list, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "test_myNN(net, test_file_list, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9f6a53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x286001dc7c0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2f3cd92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_under.csv\n",
      "Finished training  data2000_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2000_test1.csv\n",
      "Accuracy, Precision, Recall:  0.879 0.183 0.022\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "net = myNN()\n",
    "file_list = ['data2000_under.csv']\n",
    "test_file_list = ['data2000_test1.csv']\n",
    "learning_rate = 1e-3\n",
    "losses = train_myNN(model=net, file_list=file_list, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "test_myNN(net, test_file_list, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aaa09020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x286006eb1c0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7e3505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with full set of undersampled data, excluding potential outliers (financial crisis, COVID19, etc)\n",
    "file_list2 = ['data2000_under.csv', 'data2001_under.csv', 'data2002_under.csv', \\\n",
    "                  'data2003_under.csv', 'data2004_under.csv', 'data2005_under.csv', \\\n",
    "                  'data2006_under.csv', 'data2007_under.csv', 'data2008_under.csv', \\\n",
    "                  'data2011_under.csv', 'data2012_under.csv', 'data2013_under.csv', \\\n",
    "                  'data2014_under.csv', 'data2015_under.csv', 'data2016_under.csv', \\\n",
    "                  'data2017_under.csv', 'data2018_under.csv']\n",
    "test_file_list2 = ['data2000_test1.csv', 'data2001_test1.csv', 'data2002_test1.csv', \\\n",
    "                          'data2003_test1.csv', 'data2004_test1.csv', 'data2005_test1.csv', \\\n",
    "                          'data2006_test1.csv', 'data2007_test1.csv', 'data2008_test1.csv', \\\n",
    "                          'data2011_test1.csv', 'data2012_test1.csv', 'data2013_test1.csv', \\\n",
    "                          'data2014_test1.csv', 'data2015_test1.csv', 'data2016_test1.csv', \\\n",
    "                          'data2017_test1.csv', 'data2018_test1.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19176f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_under.csv\n",
      "Finished training  data2000_under.csv\n",
      "Training data file: data2001_under.csv\n",
      "Finished training  data2001_under.csv\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Training data file: data2014_under.csv\n",
      "Finished training  data2014_under.csv\n",
      "Training data file: data2015_under.csv\n",
      "Finished training  data2015_under.csv\n",
      "Training data file: data2016_under.csv\n",
      "Finished training  data2016_under.csv\n",
      "Training data file: data2017_under.csv\n",
      "Finished training  data2017_under.csv\n",
      "Training data file: data2018_under.csv\n",
      "Finished training  data2018_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2000_test1.csv\n",
      "Accuracy, Precision, Recall:  0.742 0.157 0.296\n",
      "Testing data file: data2001_test1.csv\n",
      "Accuracy, Precision, Recall:  0.828 0.154 0.199\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.786 0.15 0.245\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.813 0.125 0.212\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.728 0.119 0.323\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.657 0.117 0.394\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.63 0.116 0.403\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.57 0.138 0.521\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.663 0.196 0.356\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.686 0.148 0.361\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.758 0.098 0.275\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.607 0.11 0.452\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.545 0.116 0.536\n",
      "Testing data file: data2015_test1.csv\n",
      "Accuracy, Precision, Recall:  0.569 0.13 0.495\n",
      "Testing data file: data2016_test1.csv\n",
      "Accuracy, Precision, Recall:  0.643 0.128 0.414\n",
      "Testing data file: data2017_test1.csv\n",
      "Accuracy, Precision, Recall:  0.586 0.101 0.472\n",
      "Testing data file: data2018_test1.csv\n",
      "Accuracy, Precision, Recall:  0.552 0.132 0.539\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "net = myNN()\n",
    "learning_rate = 1e-3\n",
    "losses = train_myNN(model=net, file_list=file_list2, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "test_myNN(net, test_file_list2, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa0ed1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with single year of undersampled data\n",
    "file_list22 = ['data2000_under.csv', 'data2001_under.csv', 'data2002_under.csv', \\\n",
    "                  'data2003_under.csv', 'data2004_under.csv', 'data2005_under.csv', \\\n",
    "                  'data2006_under.csv', 'data2007_under.csv', 'data2008_under.csv', \\\n",
    "                  'data2009_under.csv', 'data2010_under.csv', \\\n",
    "                  'data2011_under.csv', 'data2012_under.csv', 'data2013_under.csv', \\\n",
    "                  'data2014_under.csv', 'data2015_under.csv', 'data2016_under.csv', \\\n",
    "                  'data2017_under.csv', 'data2018_under.csv', 'data2019_under.csv', \\\n",
    "                  'data2020_under.csv']\n",
    "test_file_list22 = ['data2000_test1.csv', 'data2001_test1.csv', 'data2002_test1.csv', \\\n",
    "                          'data2003_test1.csv', 'data2004_test1.csv', 'data2005_test1.csv', \\\n",
    "                          'data2006_test1.csv', 'data2007_test1.csv', 'data2008_test1.csv', \\\n",
    "                          'data2009_test1.csv', 'data2010_test1.csv', \\\n",
    "                          'data2011_test1.csv', 'data2012_test1.csv', 'data2013_test1.csv', \\\n",
    "                          'data2014_test1.csv', 'data2015_test1.csv', 'data2016_test1.csv', \\\n",
    "                          'data2017_test1.csv', 'data2018_test1.csv', 'data2019_test1.csv', \\\n",
    "                          'data2020_test1.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b53d50d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_under.csv\n",
      "Finished training  data2000_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2000_test1.csv\n",
      "Accuracy, Precision, Recall:  0.879 0.194 0.023\n",
      "Finished all testing...\n",
      "Training data file: data2001_under.csv\n",
      "Finished training  data2001_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2001_test1.csv\n",
      "Accuracy, Precision, Recall:  0.906 0.129 0.007\n",
      "Finished all testing...\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.894 0.14 0.012\n",
      "Finished all testing...\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.899 0.119 0.036\n",
      "Finished all testing...\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.91 0.151 0.004\n",
      "Finished all testing...\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.901 0.122 0.005\n",
      "Finished all testing...\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.896 0.142 0.005\n",
      "Finished all testing...\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.88 0.179 0.011\n",
      "Finished all testing...\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.84 0.1 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2009_under.csv\n",
      "Finished training  data2009_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2009_test1.csv\n",
      "Accuracy, Precision, Recall:  0.898 0.154 0.049\n",
      "Finished all testing...\n",
      "Training data file: data2010_under.csv\n",
      "Finished training  data2010_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2010_test1.csv\n",
      "Accuracy, Precision, Recall:  0.914 0.114 0.013\n",
      "Finished all testing...\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.853 0.155 0.06\n",
      "Finished all testing...\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.874 0.125 0.114\n",
      "Finished all testing...\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.897 0.139 0.021\n",
      "Finished all testing...\n",
      "Training data file: data2014_under.csv\n",
      "Finished training  data2014_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.893 0.15 0.014\n",
      "Finished all testing...\n",
      "Training data file: data2015_under.csv\n",
      "Finished training  data2015_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2015_test1.csv\n",
      "Accuracy, Precision, Recall:  0.878 0.176 0.023\n",
      "Finished all testing...\n",
      "Training data file: data2016_under.csv\n",
      "Finished training  data2016_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2016_test1.csv\n",
      "Accuracy, Precision, Recall:  0.858 0.139 0.068\n",
      "Finished all testing...\n",
      "Training data file: data2017_under.csv\n",
      "Finished training  data2017_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2017_test1.csv\n",
      "Accuracy, Precision, Recall:  0.903 0.148 0.023\n",
      "Finished all testing...\n",
      "Training data file: data2018_under.csv\n",
      "Finished training  data2018_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2018_test1.csv\n",
      "Accuracy, Precision, Recall:  0.884 0.139 0.008\n",
      "Finished all testing...\n",
      "Training data file: data2019_under.csv\n",
      "Finished training  data2019_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2019_test1.csv\n",
      "Accuracy, Precision, Recall:  0.894 0.155 0.006\n",
      "Finished all testing...\n",
      "Training data file: data2020_under.csv\n",
      "Finished training  data2020_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2020_test1.csv\n",
      "Accuracy, Precision, Recall:  0.821 0.242 0.03\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for i in range(len(file_list22)):\n",
    "    net = myNN()\n",
    "    file_list222 = [file_list22[i]]\n",
    "    test_file_list222 = [test_file_list22[i]]\n",
    "    losses = train_myNN(model=net, file_list=file_list222, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "    test_myNN(net, test_file_list222, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62c82b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with full set of original data, excluding potential outliers (financial crisis, COVID19, etc)\n",
    "file_list3 = ['data2000_train1.csv', 'data2001_train1.csv', 'data2002_train1.csv', \\\n",
    "                  'data2003_train1.csv', 'data2004_train1.csv', 'data2005_train1.csv', \\\n",
    "                  'data2006_train1.csv', 'data2007_train1.csv', 'data2008_train1.csv', \\\n",
    "                  'data2011_train1.csv', 'data2012_train1.csv', 'data2013_train1.csv', \\\n",
    "                  'data2014_train1.csv', 'data2015_train1.csv', 'data2016_train1.csv', \\\n",
    "                  'data2017_train1.csv', 'data2018_train1.csv']\n",
    "test_file_list3 = ['data2000_test1.csv', 'data2001_test1.csv', 'data2002_test1.csv', \\\n",
    "                          'data2003_test1.csv', 'data2004_test1.csv', 'data2005_test1.csv', \\\n",
    "                          'data2006_test1.csv', 'data2007_test1.csv', 'data2008_test1.csv', \\\n",
    "                          'data2011_test1.csv', 'data2012_test1.csv', 'data2013_test1.csv', \\\n",
    "                          'data2014_test1.csv', 'data2015_test1.csv', 'data2016_test1.csv', \\\n",
    "                          'data2017_test1.csv', 'data2018_test1.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8de25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_train1.csv\n",
      "Finished training  data2000_train1.csv\n",
      "Training data file: data2001_train1.csv\n",
      "Finished training  data2001_train1.csv\n",
      "Training data file: data2002_train1.csv\n",
      "Finished training  data2002_train1.csv\n",
      "Training data file: data2003_train1.csv\n",
      "Finished training  data2003_train1.csv\n",
      "Training data file: data2004_train1.csv\n",
      "Finished training  data2004_train1.csv\n",
      "Training data file: data2005_train1.csv\n",
      "Finished training  data2005_train1.csv\n",
      "Training data file: data2006_train1.csv\n",
      "Finished training  data2006_train1.csv\n",
      "Training data file: data2007_train1.csv\n",
      "Finished training  data2007_train1.csv\n",
      "Training data file: data2008_train1.csv\n",
      "Finished training  data2008_train1.csv\n",
      "Training data file: data2011_train1.csv\n",
      "Finished training  data2011_train1.csv\n",
      "Training data file: data2012_train1.csv\n",
      "Finished training  data2012_train1.csv\n",
      "Training data file: data2013_train1.csv\n",
      "Finished training  data2013_train1.csv\n",
      "Training data file: data2014_train1.csv\n",
      "Finished training  data2014_train1.csv\n",
      "Training data file: data2015_train1.csv\n",
      "Finished training  data2015_train1.csv\n",
      "Training data file: data2016_train1.csv\n",
      "Finished training  data2016_train1.csv\n",
      "Training data file: data2017_train1.csv\n",
      "Finished training  data2017_train1.csv\n",
      "Training data file: data2018_train1.csv\n",
      "Finished training  data2018_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2000_test1.csv\n",
      "Accuracy, Precision, Recall:  0.888 0.111 0.0\n",
      "Testing data file: data2001_test1.csv\n",
      "Accuracy, Precision, Recall:  0.909 0.171 0.0\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.9 0.054 0.0\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.917 0.167 0.0\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.911 0.2 0.0\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.904 0.0 0.0\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.899 0.133 0.0\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.885 0.0 0.0\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.84 0.25 0.0\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.884 0.0 0.0\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.925 0.0 0.0\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.907 0.143 0.0\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.9 0.205 0.0\n",
      "Testing data file: data2015_test1.csv\n",
      "Accuracy, Precision, Recall:  0.888 0.5 0.0\n",
      "Testing data file: data2016_test1.csv\n",
      "Accuracy, Precision, Recall:  0.895 0.308 0.0\n",
      "Testing data file: data2017_test1.csv\n",
      "Accuracy, Precision, Recall:  0.912 0.167 0.0\n",
      "Testing data file: data2018_test1.csv\n",
      "Accuracy, Precision, Recall:  0.888 0.185 0.0\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "net = myNN()\n",
    "learning_rate = 1e-4\n",
    "losses = train_myNN(model=net, file_list=file_list3, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "test_myNN(net, test_file_list3, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94d8e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with individual year of original data\n",
    "file_list33 = ['data2000_train1.csv', 'data2001_train1.csv', 'data2002_train1.csv', \\\n",
    "                  'data2003_train1.csv', 'data2004_train1.csv', 'data2005_train1.csv', \\\n",
    "                  'data2006_train1.csv', 'data2007_train1.csv', 'data2008_train1.csv', \\\n",
    "                  'data2009_train1.csv', 'data2010_train1.csv', \\\n",
    "                  'data2011_train1.csv', 'data2012_train1.csv', 'data2013_train1.csv', \\\n",
    "                  'data2014_train1.csv', 'data2015_train1.csv', 'data2016_train1.csv', \\\n",
    "                  'data2017_train1.csv', 'data2018_train1.csv', 'data2019_train1.csv', \\\n",
    "                  'data2020_train1.csv']\n",
    "test_file_list33 = ['data2000_test1.csv', 'data2001_test1.csv', 'data2002_test1.csv', \\\n",
    "                          'data2003_test1.csv', 'data2004_test1.csv', 'data2005_test1.csv', \\\n",
    "                          'data2006_test1.csv', 'data2007_test1.csv', 'data2008_test1.csv', \\\n",
    "                          'data2009_test1.csv', 'data2010_test1.csv', \\\n",
    "                          'data2011_test1.csv', 'data2012_test1.csv', 'data2013_test1.csv', \\\n",
    "                          'data2014_test1.csv', 'data2015_test1.csv', 'data2016_test1.csv', \\\n",
    "                          'data2017_test1.csv', 'data2018_test1.csv', 'data2019_test1.csv', \\\n",
    "                          'data2020_test1.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5079465",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_train1.csv\n",
      "Finished training  data2000_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2000_test1.csv\n",
      "Accuracy, Precision, Recall:  0.883 0.155 0.008\n",
      "Finished all testing...\n",
      "Training data file: data2001_train1.csv\n",
      "Finished training  data2001_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2001_test1.csv\n",
      "Accuracy, Precision, Recall:  0.907 0.13 0.004\n",
      "Finished all testing...\n",
      "Training data file: data2002_train1.csv\n",
      "Finished training  data2002_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.896 0.117 0.006\n",
      "Finished all testing...\n",
      "Training data file: data2003_train1.csv\n",
      "Finished training  data2003_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.914 0.089 0.004\n",
      "Finished all testing...\n",
      "Training data file: data2004_train1.csv\n",
      "Finished training  data2004_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.905 0.076 0.006\n",
      "Finished all testing...\n",
      "Training data file: data2005_train1.csv\n",
      "Finished training  data2005_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.9 0.084 0.004\n",
      "Finished all testing...\n",
      "Training data file: data2006_train1.csv\n",
      "Finished training  data2006_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.896 0.098 0.004\n",
      "Finished all testing...\n",
      "Training data file: data2007_train1.csv\n",
      "Finished training  data2007_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.882 0.147 0.005\n",
      "Finished all testing...\n",
      "Training data file: data2008_train1.csv\n",
      "Finished training  data2008_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.839 0.199 0.002\n",
      "Finished all testing...\n",
      "Training data file: data2009_train1.csv\n",
      "Finished training  data2009_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2009_test1.csv\n",
      "Accuracy, Precision, Recall:  0.913 0.087 0.004\n",
      "Finished all testing...\n",
      "Training data file: data2010_train1.csv\n",
      "Finished training  data2010_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2010_test1.csv\n",
      "Accuracy, Precision, Recall:  0.919 0.126 0.004\n",
      "Finished all testing...\n",
      "Training data file: data2011_train1.csv\n",
      "Finished training  data2011_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.878 0.126 0.008\n",
      "Finished all testing...\n",
      "Training data file: data2012_train1.csv\n",
      "Finished training  data2012_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.917 0.114 0.017\n",
      "Finished all testing...\n",
      "Training data file: data2013_train1.csv\n",
      "Finished training  data2013_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.905 0.121 0.003\n",
      "Finished all testing...\n",
      "Training data file: data2014_train1.csv\n",
      "Finished training  data2014_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.894 0.098 0.007\n",
      "Finished all testing...\n",
      "Training data file: data2015_train1.csv\n",
      "Finished training  data2015_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2015_test1.csv\n",
      "Accuracy, Precision, Recall:  0.884 0.138 0.006\n",
      "Finished all testing...\n",
      "Training data file: data2016_train1.csv\n",
      "Finished training  data2016_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2016_test1.csv\n",
      "Accuracy, Precision, Recall:  0.894 0.124 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2017_train1.csv\n",
      "Finished training  data2017_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2017_test1.csv\n",
      "Accuracy, Precision, Recall:  0.906 0.114 0.011\n",
      "Finished all testing...\n",
      "Training data file: data2018_train1.csv\n",
      "Finished training  data2018_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2018_test1.csv\n",
      "Accuracy, Precision, Recall:  0.886 0.131 0.003\n",
      "Finished all testing...\n",
      "Training data file: data2019_train1.csv\n",
      "Finished training  data2019_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2019_test1.csv\n",
      "Accuracy, Precision, Recall:  0.897 0.161 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2020_train1.csv\n",
      "Finished training  data2020_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2020_test1.csv\n",
      "Accuracy, Precision, Recall:  0.794 0.199 0.074\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "for i in range(len(file_list33)):\n",
    "    net = myNN()\n",
    "    file_list333 = [file_list33[i]]\n",
    "    test_file_list333 = [test_file_list33[i]]\n",
    "    losses = train_myNN(model=net, file_list=file_list333, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "    test_myNN(net, test_file_list333, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6229db87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_under.csv\n",
      "Finished training  data2000_under.csv\n",
      "Training data file: data2001_under.csv\n",
      "Finished training  data2001_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2001_test1.csv\n",
      "Accuracy, Precision, Recall:  0.886 0.178 0.072\n",
      "Finished all testing...\n",
      "Training data file: data2001_under.csv\n",
      "Finished training  data2001_under.csv\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.885 0.206 0.052\n",
      "Finished all testing...\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.889 0.148 0.072\n",
      "Finished all testing...\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.911 0.167 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.904 0.188 0.002\n",
      "Finished all testing...\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.889 0.162 0.025\n",
      "Finished all testing...\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.884 0.16 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.839 0.321 0.002\n",
      "Finished all testing...\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.863 0.16 0.043\n",
      "Finished all testing...\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.913 0.149 0.036\n",
      "Finished all testing...\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.896 0.135 0.021\n",
      "Finished all testing...\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Training data file: data2014_under.csv\n",
      "Finished training  data2014_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2014_test1.csv\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-b2bc811b6550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtest_file_list22\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_file_list2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_myNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_list22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtest_myNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_file_list22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-dcb78b9f3962>\u001b[0m in \u001b[0;36mtest_myNN\u001b[1;34m(model, file_list, cols)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mFN\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy, Precision, Recall: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#use 2 prior years of undersampled data\n",
    "learning_rate = 1e-3\n",
    "for i in range(len(file_list2)-1):\n",
    "    net = myNN()\n",
    "    file_list22 = [file_list2[i], file_list2[i+1]]\n",
    "    test_file_list22 = [test_file_list2[i+1]]\n",
    "    losses = train_myNN(model=net, file_list=file_list22, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "    test_myNN(net, test_file_list22, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3e61c24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_under.csv\n",
      "Finished training  data2000_under.csv\n",
      "Training data file: data2001_under.csv\n",
      "Finished training  data2001_under.csv\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.858 0.169 0.107\n",
      "Finished all testing...\n",
      "Training data file: data2001_under.csv\n",
      "Finished training  data2001_under.csv\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.857 0.139 0.141\n",
      "Finished all testing...\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.91 0.23 0.005\n",
      "Finished all testing...\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.902 0.144 0.004\n",
      "Finished all testing...\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.886 0.157 0.031\n",
      "Finished all testing...\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.884 0.21 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.838 0.276 0.008\n",
      "Finished all testing...\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.881 0.196 0.009\n",
      "Finished all testing...\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.9 0.144 0.068\n",
      "Finished all testing...\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.901 0.148 0.013\n",
      "Finished all testing...\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Training data file: data2014_under.csv\n",
      "Finished training  data2014_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.899 0.1 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Training data file: data2014_under.csv\n",
      "Finished training  data2014_under.csv\n",
      "Training data file: data2015_under.csv\n",
      "Finished training  data2015_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2015_test1.csv\n",
      "Accuracy, Precision, Recall:  0.887 0.164 0.002\n",
      "Finished all testing...\n",
      "Training data file: data2014_under.csv\n",
      "Finished training  data2014_under.csv\n",
      "Training data file: data2015_under.csv\n",
      "Finished training  data2015_under.csv\n",
      "Training data file: data2016_under.csv\n",
      "Finished training  data2016_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2016_test1.csv\n",
      "Accuracy, Precision, Recall:  0.867 0.15 0.057\n",
      "Finished all testing...\n",
      "Training data file: data2015_under.csv\n",
      "Finished training  data2015_under.csv\n",
      "Training data file: data2016_under.csv\n",
      "Finished training  data2016_under.csv\n",
      "Training data file: data2017_under.csv\n",
      "Finished training  data2017_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2017_test1.csv\n",
      "Accuracy, Precision, Recall:  0.91 0.161 0.006\n",
      "Finished all testing...\n",
      "Training data file: data2016_under.csv\n",
      "Finished training  data2016_under.csv\n",
      "Training data file: data2017_under.csv\n",
      "Finished training  data2017_under.csv\n",
      "Training data file: data2018_under.csv\n",
      "Finished training  data2018_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2018_test1.csv\n",
      "Accuracy, Precision, Recall:  0.886 0.142 0.004\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "#use 3 prior years of undersampled data\n",
    "learning_rate = 1e-3\n",
    "for i in range(len(file_list2)-2):\n",
    "    net = myNN()\n",
    "    file_list22 = [file_list2[i], file_list2[i+1], file_list2[i+2]]\n",
    "    test_file_list22 = [test_file_list2[i+2]]\n",
    "    losses = train_myNN(model=net, file_list=file_list22, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "    test_myNN(net, test_file_list22, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad6d089f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_train1.csv\n",
      "Finished training  data2000_train1.csv\n",
      "Training data file: data2001_train1.csv\n",
      "Finished training  data2001_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2001_test1.csv\n",
      "Accuracy, Precision, Recall:  0.909 0.112 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2001_train1.csv\n",
      "Finished training  data2001_train1.csv\n",
      "Training data file: data2002_train1.csv\n",
      "Finished training  data2002_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.898 0.101 0.002\n",
      "Finished all testing...\n",
      "Training data file: data2002_train1.csv\n",
      "Finished training  data2002_train1.csv\n",
      "Training data file: data2003_train1.csv\n",
      "Finished training  data2003_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.917 0.092 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2003_train1.csv\n",
      "Finished training  data2003_train1.csv\n",
      "Training data file: data2004_train1.csv\n",
      "Finished training  data2004_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.91 0.08 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2004_train1.csv\n",
      "Finished training  data2004_train1.csv\n",
      "Training data file: data2005_train1.csv\n",
      "Finished training  data2005_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.904 0.15 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2005_train1.csv\n",
      "Finished training  data2005_train1.csv\n",
      "Training data file: data2006_train1.csv\n",
      "Finished training  data2006_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.898 0.115 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2006_train1.csv\n",
      "Finished training  data2006_train1.csv\n",
      "Training data file: data2007_train1.csv\n",
      "Finished training  data2007_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.884 0.109 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2007_train1.csv\n",
      "Finished training  data2007_train1.csv\n",
      "Training data file: data2008_train1.csv\n",
      "Finished training  data2008_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.839 0.167 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2008_train1.csv\n",
      "Finished training  data2008_train1.csv\n",
      "Training data file: data2011_train1.csv\n",
      "Finished training  data2011_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.884 0.176 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2011_train1.csv\n",
      "Finished training  data2011_train1.csv\n",
      "Training data file: data2012_train1.csv\n",
      "Finished training  data2012_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.925 0.1 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2012_train1.csv\n",
      "Finished training  data2012_train1.csv\n",
      "Training data file: data2013_train1.csv\n",
      "Finished training  data2013_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.906 0.023 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2013_train1.csv\n",
      "Finished training  data2013_train1.csv\n",
      "Training data file: data2014_train1.csv\n",
      "Finished training  data2014_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.899 0.057 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2014_train1.csv\n",
      "Finished training  data2014_train1.csv\n",
      "Training data file: data2015_train1.csv\n",
      "Finished training  data2015_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2015_test1.csv\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-971ecfea08b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtest_file_list33\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_file_list3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_myNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_list33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtest_myNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_file_list33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-dcb78b9f3962>\u001b[0m in \u001b[0;36mtest_myNN\u001b[1;34m(model, file_list, cols)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mFN\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy, Precision, Recall: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#use 2 prior years of original data\n",
    "learning_rate = 1e-4\n",
    "for i in range(len(file_list3)-1):\n",
    "    net = myNN()\n",
    "    file_list33 = [file_list3[i], file_list3[i+1]]\n",
    "    test_file_list33 = [test_file_list3[i+1]]\n",
    "    losses = train_myNN(model=net, file_list=file_list33, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "    test_myNN(net, test_file_list33, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63e3dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_train1.csv\n",
      "Finished training  data2000_train1.csv\n",
      "Training data file: data2001_train1.csv\n",
      "Finished training  data2001_train1.csv\n",
      "Training data file: data2002_train1.csv\n",
      "Finished training  data2002_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.899 0.155 0.002\n",
      "Finished all testing...\n",
      "Training data file: data2001_train1.csv\n",
      "Finished training  data2001_train1.csv\n",
      "Training data file: data2002_train1.csv\n",
      "Finished training  data2002_train1.csv\n",
      "Training data file: data2003_train1.csv\n",
      "Finished training  data2003_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.918 0.25 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2002_train1.csv\n",
      "Finished training  data2002_train1.csv\n",
      "Training data file: data2003_train1.csv\n",
      "Finished training  data2003_train1.csv\n",
      "Training data file: data2004_train1.csv\n",
      "Finished training  data2004_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.911 0.154 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2003_train1.csv\n",
      "Finished training  data2003_train1.csv\n",
      "Training data file: data2004_train1.csv\n",
      "Finished training  data2004_train1.csv\n",
      "Training data file: data2005_train1.csv\n",
      "Finished training  data2005_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.904 0.0 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2004_train1.csv\n",
      "Finished training  data2004_train1.csv\n",
      "Training data file: data2005_train1.csv\n",
      "Finished training  data2005_train1.csv\n",
      "Training data file: data2006_train1.csv\n",
      "Finished training  data2006_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.899 0.211 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2005_train1.csv\n",
      "Finished training  data2005_train1.csv\n",
      "Training data file: data2006_train1.csv\n",
      "Finished training  data2006_train1.csv\n",
      "Training data file: data2007_train1.csv\n",
      "Finished training  data2007_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.884 0.139 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2006_train1.csv\n",
      "Finished training  data2006_train1.csv\n",
      "Training data file: data2007_train1.csv\n",
      "Finished training  data2007_train1.csv\n",
      "Training data file: data2008_train1.csv\n",
      "Finished training  data2008_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.839 0.195 0.002\n",
      "Finished all testing...\n",
      "Training data file: data2007_train1.csv\n",
      "Finished training  data2007_train1.csv\n",
      "Training data file: data2008_train1.csv\n",
      "Finished training  data2008_train1.csv\n",
      "Training data file: data2011_train1.csv\n",
      "Finished training  data2011_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.883 0.105 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2008_train1.csv\n",
      "Finished training  data2008_train1.csv\n",
      "Training data file: data2011_train1.csv\n",
      "Finished training  data2011_train1.csv\n",
      "Training data file: data2012_train1.csv\n",
      "Finished training  data2012_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.924 0.098 0.002\n",
      "Finished all testing...\n",
      "Training data file: data2011_train1.csv\n",
      "Finished training  data2011_train1.csv\n",
      "Training data file: data2012_train1.csv\n",
      "Finished training  data2012_train1.csv\n",
      "Training data file: data2013_train1.csv\n",
      "Finished training  data2013_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.906 0.136 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2012_train1.csv\n",
      "Finished training  data2012_train1.csv\n",
      "Training data file: data2013_train1.csv\n",
      "Finished training  data2013_train1.csv\n",
      "Training data file: data2014_train1.csv\n",
      "Finished training  data2014_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.899 0.145 0.001\n",
      "Finished all testing...\n",
      "Training data file: data2013_train1.csv\n",
      "Finished training  data2013_train1.csv\n",
      "Training data file: data2014_train1.csv\n",
      "Finished training  data2014_train1.csv\n",
      "Training data file: data2015_train1.csv\n",
      "Finished training  data2015_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2015_test1.csv\n",
      "Accuracy, Precision, Recall:  0.887 0.192 0.0\n",
      "Finished all testing...\n",
      "Training data file: data2014_train1.csv\n",
      "Finished training  data2014_train1.csv\n",
      "Training data file: data2015_train1.csv\n",
      "Finished training  data2015_train1.csv\n",
      "Training data file: data2016_train1.csv\n",
      "Finished training  data2016_train1.csv\n",
      "Finished all training...\n",
      "Testing data file: data2016_test1.csv\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-6e0cbae4498b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtest_file_list33\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_file_list3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_myNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_list33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtest_myNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_file_list33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-dcb78b9f3962>\u001b[0m in \u001b[0;36mtest_myNN\u001b[1;34m(model, file_list, cols)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mFN\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy, Precision, Recall: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#use 3 prior years of original data\n",
    "learning_rate = 1e-4\n",
    "for i in range(len(file_list3)-2):\n",
    "    net = myNN()\n",
    "    file_list33 = [file_list3[i], file_list3[i+1], file_list3[i+2]]\n",
    "    test_file_list33 = [test_file_list3[i+2]]\n",
    "    losses = train_myNN(model=net, file_list=file_list33, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate)\n",
    "    test_myNN(net, test_file_list33, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9f259846",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_under.csv\n",
      "Finished training  data2000_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2000_test1.csv\n",
      "Accuracy, Precision, Recall:  0.797 0.147 0.168\n",
      "Finished all testing...\n",
      "Training data file: data2001_under.csv\n",
      "Finished training  data2001_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2001_test1.csv\n",
      "Accuracy, Precision, Recall:  0.734 0.117 0.297\n",
      "Finished all testing...\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.674 0.116 0.34\n",
      "Finished all testing...\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.61 0.093 0.428\n",
      "Finished all testing...\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.373 0.092 0.679\n",
      "Finished all testing...\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.726 0.109 0.261\n",
      "Finished all testing...\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.562 0.114 0.492\n",
      "Finished all testing...\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.723 0.137 0.265\n",
      "Finished all testing...\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.808 0.207 0.071\n",
      "Finished all testing...\n",
      "Training data file: data2009_under.csv\n",
      "Finished training  data2009_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2009_test1.csv\n",
      "Accuracy, Precision, Recall:  0.439 0.091 0.635\n",
      "Finished all testing...\n",
      "Training data file: data2010_under.csv\n",
      "Finished training  data2010_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2010_test1.csv\n",
      "Accuracy, Precision, Recall:  0.513 0.085 0.527\n",
      "Finished all testing...\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.549 0.131 0.513\n",
      "Finished all testing...\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.695 0.1 0.385\n",
      "Finished all testing...\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.745 0.115 0.258\n",
      "Finished all testing...\n",
      "Training data file: data2014_under.csv\n",
      "Finished training  data2014_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.534 0.113 0.532\n",
      "Finished all testing...\n",
      "Training data file: data2015_under.csv\n",
      "Finished training  data2015_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2015_test1.csv\n",
      "Accuracy, Precision, Recall:  0.735 0.14 0.263\n",
      "Finished all testing...\n",
      "Training data file: data2016_under.csv\n",
      "Finished training  data2016_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2016_test1.csv\n",
      "Accuracy, Precision, Recall:  0.687 0.128 0.34\n",
      "Finished all testing...\n",
      "Training data file: data2017_under.csv\n",
      "Finished training  data2017_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2017_test1.csv\n",
      "Accuracy, Precision, Recall:  0.488 0.1 0.603\n",
      "Finished all testing...\n",
      "Training data file: data2018_under.csv\n",
      "Finished training  data2018_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2018_test1.csv\n",
      "Accuracy, Precision, Recall:  0.723 0.128 0.254\n",
      "Finished all testing...\n",
      "Training data file: data2019_under.csv\n",
      "Finished training  data2019_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2019_test1.csv\n",
      "Accuracy, Precision, Recall:  0.338 0.108 0.749\n",
      "Finished all testing...\n",
      "Training data file: data2020_under.csv\n",
      "Finished training  data2020_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2020_test1.csv\n",
      "Accuracy, Precision, Recall:  0.537 0.207 0.622\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "#train with more epochs\n",
    "learning_rate = 1e-5\n",
    "Epochs = 2\n",
    "for i in range(len(file_list2)):\n",
    "    net = myNN()\n",
    "    file_list22 = [file_list2[i]]\n",
    "    test_file_list22 = [test_file_list2[i]]\n",
    "    losses = train_myNN2(model=net, file_list=file_list22, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate, epochs=Epochs)\n",
    "    test_myNN(net, test_file_list22, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76c779c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data file: data2000_under.csv\n",
      "Finished training  data2000_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2000_test1.csv\n",
      "Accuracy, Precision, Recall:  0.828 0.156 0.121\n",
      "Finished all testing...\n",
      "Training data file: data2001_under.csv\n",
      "Finished training  data2001_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2001_test1.csv\n",
      "Accuracy, Precision, Recall:  0.608 0.109 0.462\n",
      "Finished all testing...\n",
      "Training data file: data2002_under.csv\n",
      "Finished training  data2002_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2002_test1.csv\n",
      "Accuracy, Precision, Recall:  0.822 0.124 0.127\n",
      "Finished all testing...\n",
      "Training data file: data2003_under.csv\n",
      "Finished training  data2003_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2003_test1.csv\n",
      "Accuracy, Precision, Recall:  0.842 0.107 0.124\n",
      "Finished all testing...\n",
      "Training data file: data2004_under.csv\n",
      "Finished training  data2004_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2004_test1.csv\n",
      "Accuracy, Precision, Recall:  0.871 0.105 0.059\n",
      "Finished all testing...\n",
      "Training data file: data2005_under.csv\n",
      "Finished training  data2005_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2005_test1.csv\n",
      "Accuracy, Precision, Recall:  0.82 0.114 0.13\n",
      "Finished all testing...\n",
      "Training data file: data2006_under.csv\n",
      "Finished training  data2006_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2006_test1.csv\n",
      "Accuracy, Precision, Recall:  0.801 0.126 0.164\n",
      "Finished all testing...\n",
      "Training data file: data2007_under.csv\n",
      "Finished training  data2007_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2007_test1.csv\n",
      "Accuracy, Precision, Recall:  0.81 0.148 0.136\n",
      "Finished all testing...\n",
      "Training data file: data2008_under.csv\n",
      "Finished training  data2008_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2008_test1.csv\n",
      "Accuracy, Precision, Recall:  0.812 0.214 0.065\n",
      "Finished all testing...\n",
      "Training data file: data2009_under.csv\n",
      "Finished training  data2009_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2009_test1.csv\n",
      "Accuracy, Precision, Recall:  0.646 0.109 0.452\n",
      "Finished all testing...\n",
      "Training data file: data2010_under.csv\n",
      "Finished training  data2010_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2010_test1.csv\n",
      "Accuracy, Precision, Recall:  0.809 0.097 0.169\n",
      "Finished all testing...\n",
      "Training data file: data2011_under.csv\n",
      "Finished training  data2011_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2011_test1.csv\n",
      "Accuracy, Precision, Recall:  0.703 0.14 0.303\n",
      "Finished all testing...\n",
      "Training data file: data2012_under.csv\n",
      "Finished training  data2012_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2012_test1.csv\n",
      "Accuracy, Precision, Recall:  0.727 0.098 0.325\n",
      "Finished all testing...\n",
      "Training data file: data2013_under.csv\n",
      "Finished training  data2013_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2013_test1.csv\n",
      "Accuracy, Precision, Recall:  0.79 0.119 0.194\n",
      "Finished all testing...\n",
      "Training data file: data2014_under.csv\n",
      "Finished training  data2014_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2014_test1.csv\n",
      "Accuracy, Precision, Recall:  0.758 0.124 0.233\n",
      "Finished all testing...\n",
      "Training data file: data2015_under.csv\n",
      "Finished training  data2015_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2015_test1.csv\n",
      "Accuracy, Precision, Recall:  0.748 0.144 0.253\n",
      "Finished all testing...\n",
      "Training data file: data2016_under.csv\n",
      "Finished training  data2016_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2016_test1.csv\n",
      "Accuracy, Precision, Recall:  0.778 0.134 0.204\n",
      "Finished all testing...\n",
      "Training data file: data2017_under.csv\n",
      "Finished training  data2017_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2017_test1.csv\n",
      "Accuracy, Precision, Recall:  0.714 0.11 0.318\n",
      "Finished all testing...\n",
      "Training data file: data2018_under.csv\n",
      "Finished training  data2018_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2018_test1.csv\n",
      "Accuracy, Precision, Recall:  0.796 0.139 0.157\n",
      "Finished all testing...\n",
      "Training data file: data2019_under.csv\n",
      "Finished training  data2019_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2019_test1.csv\n",
      "Accuracy, Precision, Recall:  0.736 0.127 0.268\n",
      "Finished all testing...\n",
      "Training data file: data2020_under.csv\n",
      "Finished training  data2020_under.csv\n",
      "Finished all training...\n",
      "Testing data file: data2020_test1.csv\n",
      "Accuracy, Precision, Recall:  0.6 0.216 0.524\n",
      "Finished all testing...\n"
     ]
    }
   ],
   "source": [
    "#train with more epochs\n",
    "learning_rate = 1e-5\n",
    "Epochs = 5\n",
    "for i in range(len(file_list2)):\n",
    "    net = myNN()\n",
    "    file_list22 = [file_list2[i]]\n",
    "    test_file_list22 = [test_file_list2[i]]\n",
    "    losses = train_myNN2(model=net, file_list=file_list22, chunk_size=chunk_size, batch_size=128, cols=cols, learning_rate=learning_rate, epochs=Epochs)\n",
    "    test_myNN(net, test_file_list22, cols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496457cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-10\n",
      "Accuracy, Precision, Recall:  0.515 0.508 0.639\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.515 0.514 0.642\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.518 0.515 0.642\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.512 0.51 0.633\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.509 0.506 0.747\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.514 0.511 0.661\n",
      "Learning rate:  1e-09\n",
      "Accuracy, Precision, Recall:  0.494 0.491 0.603\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.494 0.497 0.602\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.497 0.499 0.606\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.492 0.494 0.602\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.508 0.511 0.432\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.497 0.498 0.569\n",
      "Learning rate:  1e-08\n",
      "Accuracy, Precision, Recall:  0.51 0.503 0.736\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.515 0.512 0.737\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.517 0.512 0.734\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.511 0.508 0.728\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.52 0.517 0.651\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.515 0.511 0.717\n",
      "Learning rate:  1e-07\n",
      "Accuracy, Precision, Recall:  0.515 0.518 0.281\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.514 0.532 0.279\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.52 0.54 0.286\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.515 0.531 0.277\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.508 0.511 0.39\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.514 0.526 0.303\n",
      "Learning rate:  1e-06\n",
      "Accuracy, Precision, Recall:  0.492 0.491 0.765\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.508 0.508 0.669\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.524 0.524 0.557\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.525 0.528 0.474\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.525 0.531 0.448\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.515 0.516 0.583\n",
      "Learning rate:  1e-05\n",
      "Accuracy, Precision, Recall:  0.528 0.533 0.366\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.524 0.553 0.281\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.529 0.582 0.213\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.521 0.567 0.182\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.526 0.589 0.177\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.526 0.565 0.244\n",
      "Learning rate:  0.0001\n",
      "Accuracy, Precision, Recall:  0.525 0.591 0.129\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.513 0.62 0.081\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.514 0.645 0.067\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.511 0.63 0.057\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.51 0.645 0.047\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.515 0.626 0.076\n",
      "Learning rate:  0.001\n",
      "Accuracy, Precision, Recall:  0.514 0.647 0.04\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.507 0.666 0.037\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.507 0.691 0.03\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.518 0.685 0.069\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.531 0.658 0.133\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.515 0.669 0.062\n",
      "Learning rate:  0.01\n",
      "Accuracy, Precision, Recall:  0.516 0.646 0.046\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.507 0.723 0.031\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.518 0.675 0.071\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.506 0.684 0.026\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.535 0.639 0.164\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.516 0.674 0.068\n",
      "Learning rate:  0.1\n",
      "Accuracy, Precision, Recall:  0.507 0.635 0.006\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.497 0.553 0.001\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.499 0.684 0.001\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.499 0.649 0.001\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.499 0.564 0.002\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.5 0.617 0.002\n",
      "Learning rate:  1.0\n",
      "Accuracy, Precision, Recall:  0.495 0.494 0.996\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.502 0.502 0.998\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.501 0.501 0.998\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.5 0.501 0.998\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.5 0.501 0.997\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.5 0.5 0.997\n"
     ]
    }
   ],
   "source": [
    "#tune learning rate with cross validation\n",
    "learning_rates = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "df = pd.read_csv('D:\\\\Stock Data\\\\data2000_under.csv', usecols=cols)\n",
    "kf5 = KFold(n_splits=5, shuffle=False)\n",
    "for lr in learning_rates:\n",
    "    net = myNN() \n",
    "    print('Learning rate: ', lr)\n",
    "    acc, pre, rec = np.zeros(5), np.zeros(5), np.zeros(5)\n",
    "    for i, (train_ind, test_ind) in enumerate(kf5.split(df)):\n",
    "        df_train = df.iloc[train_ind]\n",
    "        df_test = df.iloc[test_ind]\n",
    "        Xtrain = df_train.drop(['labels'], axis=1)\n",
    "        ytrain = df_train['labels']\n",
    "        Xtest = torch.tensor(df_test.drop(['labels'], axis=1).values).float()\n",
    "        ytest = torch.tensor(df_test['labels'].values).float()\n",
    "        train_myNNcv(net, Xtrain, ytrain, chunk_size=chunk_size, batch_size=batch_size, learning_rate=lr)\n",
    "        acc[i], pre[i], rec[i] = test_myNNcv(net, Xtest, ytest)\n",
    "    print('Average Accuracy, Precision, Recall: ', np.round(np.mean(acc), 3), \\\n",
    "            np.round(np.mean(pre), 3), np.round(np.mean(rec), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e8772fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-10\n",
      "Accuracy, Precision, Recall:  0.815 0.146 0.128\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.813 0.141 0.128\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.813 0.142 0.128\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.815 0.144 0.128\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.731 0.114 0.201\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.797 0.137 0.143\n",
      "Learning rate:  1e-09\n",
      "Accuracy, Precision, Recall:  0.768 0.138 0.197\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.766 0.135 0.197\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.766 0.136 0.196\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.768 0.136 0.195\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.755 0.135 0.212\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.765 0.136 0.199\n",
      "Learning rate:  1e-08\n",
      "Accuracy, Precision, Recall:  0.36 0.119 0.723\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.358 0.118 0.722\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.358 0.118 0.718\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.36 0.118 0.719\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.447 0.123 0.628\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.377 0.119 0.702\n",
      "Learning rate:  1e-07\n",
      "Accuracy, Precision, Recall:  0.482 0.108 0.491\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.504 0.109 0.471\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.525 0.112 0.457\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.545 0.112 0.432\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.65 0.121 0.33\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.541 0.112 0.436\n",
      "Learning rate:  1e-06\n",
      "Accuracy, Precision, Recall:  0.297 0.113 0.757\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.29 0.114 0.779\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.289 0.116 0.79\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.287 0.116 0.798\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.586 0.128 0.456\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.35 0.117 0.716\n",
      "Learning rate:  1e-05\n",
      "Accuracy, Precision, Recall:  0.803 0.153 0.16\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.838 0.153 0.095\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.863 0.17 0.053\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.873 0.169 0.029\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.878 0.148 0.016\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.851 0.159 0.071\n",
      "Learning rate:  0.0001\n",
      "Accuracy, Precision, Recall:  0.885 0.144 0.002\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.886 0.146 0.001\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.886 0.0 0.0\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.886 0.0 0.0\n",
      "Finished all testing...\n",
      "Accuracy, Precision, Recall:  0.886 0.5 0.0\n",
      "Finished all testing...\n",
      "Average Accuracy, Precision, Recall:  0.886 0.158 0.0\n",
      "Learning rate:  0.001\n",
      "Accuracy, Precision, Recall:  0.885 0.105 0.001\n",
      "Finished all testing...\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c6d13323b5a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtrain_myNNcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_myNNcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     print('Average Accuracy, Precision, Recall: ', np.round(np.mean(acc), 3), \\\n\u001b[0;32m     18\u001b[0m             np.round(np.mean(pre), 3), np.round(np.mean(rec), 3))\n",
      "\u001b[1;32m<ipython-input-3-266948f9509b>\u001b[0m in \u001b[0;36mtest_myNNcv\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mFN\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy, Precision, Recall: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "df = pd.read_csv('D:\\\\Stock Data\\\\data2000_train1.csv', usecols=cols)\n",
    "kf5 = KFold(n_splits=5, shuffle=False)\n",
    "for lr in learning_rates:\n",
    "    net = myNN() \n",
    "    print('Learning rate: ', lr)\n",
    "    acc, pre, rec = np.zeros(5), np.zeros(5), np.zeros(5)\n",
    "    for i, (train_ind, test_ind) in enumerate(kf5.split(df)):\n",
    "        df_train = df.iloc[train_ind]\n",
    "        df_test = df.iloc[test_ind]\n",
    "        Xtrain = df_train.drop(['labels'], axis=1)\n",
    "        ytrain = df_train['labels']\n",
    "        Xtest = torch.tensor(df_test.drop(['labels'], axis=1).values).float()\n",
    "        ytest = torch.tensor(df_test['labels'].values).float()\n",
    "        train_myNNcv(net, Xtrain, ytrain, chunk_size=chunk_size, batch_size=batch_size, learning_rate=lr)\n",
    "        acc[i], pre[i], rec[i] = test_myNNcv(net, Xtest, ytest)\n",
    "    print('Average Accuracy, Precision, Recall: ', np.round(np.mean(acc), 3), \\\n",
    "            np.round(np.mean(pre), 3), np.round(np.mean(rec), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdf498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
